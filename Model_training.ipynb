{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from CNN_model_v3 import * \n",
    "from CNN_RNN_v3 import * \n",
    "from CNN_RNN_att_v3 import * \n",
    "from raim_v3 import *\n",
    "from raim_model_w_att import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1. Train CNN on short-term (hourly) ECG signals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "9/9 [==============================] - 11s - loss: 0.9249 - acc: 0.2222    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d7a8fd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = cnn_model()\n",
    "X = np.random.randn(10, 450000, 1)\n",
    "Y = np.ones((10))\n",
    "Y[:5]=0\n",
    "values = Y\n",
    "\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "Y = onehot_encoded\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(X, Y, test_size=0.1, random_state=0)\n",
    "\n",
    "filepath=\"./m_weights-CNN_DC-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "\n",
    "# if the accuracy does not increase over 10 epochs, we reduce the learning rate by half.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=10, min_lr=0.0001, verbose=1)\n",
    "metrics_history = MetricsHistory()\n",
    "\n",
    "\n",
    "model.fit(x= x_tr,\n",
    "          y= y_tr,\n",
    "          batch_size=1,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train CNN-RNN on long-term (e.g., 12-hr) sequences¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, None, 3750, 1)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, None, 64)          250416    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, None, 200)         132000    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_10 (Bidirectio (None, None, 200)         240800    \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, None, 2)           402       \n",
      "=================================================================\n",
      "Total params: 623,618\n",
      "Trainable params: 623,618\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "Epoch 00000: val_acc improved from -inf to 0.71000, saving model to lstm_model.h5\n",
      "8s - loss: 0.6790 - acc: 0.6900 - val_loss: 0.6629 - val_acc: 0.7100\n",
      "Epoch 2/2\n",
      "Epoch 00001: val_acc improved from 0.71000 to 0.97000, saving model to lstm_model.h5\n",
      "2s - loss: 0.4797 - acc: 0.9000 - val_loss: 0.1310 - val_acc: 0.9700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1338dca90>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_lstm_w_att()\n",
    "\n",
    "file_path = \"lstm_model.h5\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=20, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "base_path = \"./test_data/\"\n",
    "\n",
    "files = glob.glob((os.path.join(base_path, \"*.npz\")))\n",
    "\n",
    "ids = sorted(list(set([x.split(\"/\")[-1][:6] for x in files])))\n",
    "#split by test subject\n",
    "train_ids, test_ids = train_test_split(ids, test_size=0.15, random_state=1338)\n",
    "\n",
    "train_val, test = [x for x in files if x.split(\"/\")[-1][:6] in train_ids],\\\n",
    "                  [x for x in files if x.split(\"/\")[-1][:6] in test_ids]\n",
    "\n",
    "train, val = train_test_split(train_val, test_size=0.1, random_state=1337)\n",
    "\n",
    "train_dict = {k: np.load(k) for k in train}\n",
    "test_dict = {k: np.load(k) for k in test}\n",
    "val_dict = {k: np.load(k) for k in val}\n",
    "\n",
    "\n",
    "model.fit_generator(gen(train_dict, aug=False), validation_data=gen(val_dict), epochs=2, verbose=2,\n",
    "                    steps_per_epoch=10, validation_steps=10, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train CNN-AttRNN on long-term sequences¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_13 (InputLayer)            (None, None, 3750, 1) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_11 (TimeDistrib (None, None, 64)      250416      input_13[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_13 (Bidirectional) (None, None, 200)     132000      time_distributed_11[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)             (None, None, 200)     0           bidirectional_13[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_14 (Bidirectional) (None, None, 200)     240800      dropout_21[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_12 (TimeDistrib (None, None, 200)     40200       bidirectional_14[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)            (None, None, 200)     0           bidirectional_14[0][0]           \n",
      "                                                                   time_distributed_12[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)               (None, None, 2)       402         multiply_5[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 663,818\n",
      "Trainable params: 663,818\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Epoch 1/2\n",
      "Epoch 00000: val_acc improved from -inf to 0.81000, saving model to lstm_model.h5\n",
      "14s - loss: 0.6935 - acc: 0.4400 - val_loss: 0.6914 - val_acc: 0.8100\n",
      "Epoch 2/2\n",
      "Epoch 00001: val_acc improved from 0.81000 to 1.00000, saving model to lstm_model.h5\n",
      "2s - loss: 0.6875 - acc: 0.9900 - val_loss: 0.6817 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1338dcc90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model_lstm()\n",
    "\n",
    "file_path = \"lstm_model.h5\"\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=20, verbose=1)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=2)\n",
    "callbacks_list = [checkpoint, early, redonplat]  # early\n",
    "\n",
    "base_path = \"./test_data/\"\n",
    "\n",
    "files = glob.glob((os.path.join(base_path, \"*.npz\")))\n",
    "\n",
    "ids = sorted(list(set([x.split(\"/\")[-1][:6] for x in files])))\n",
    "#split by test subject\n",
    "train_ids, test_ids = train_test_split(ids, test_size=0.15, random_state=1338)\n",
    "\n",
    "train_val, test = [x for x in files if x.split(\"/\")[-1][:6] in train_ids],\\\n",
    "                  [x for x in files if x.split(\"/\")[-1][:6] in test_ids]\n",
    "\n",
    "train, val = train_test_split(train_val, test_size=0.1, random_state=1337)\n",
    "\n",
    "train_dict = {k: np.load(k) for k in train}\n",
    "test_dict = {k: np.load(k) for k in test}\n",
    "val_dict = {k: np.load(k) for k in val}\n",
    "\n",
    "\n",
    "model.fit_generator(gen(train_dict, aug=False), validation_data=gen(val_dict), epochs=2, verbose=2,\n",
    "                    steps_per_epoch=10, validation_steps=10, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train RAIM with lab-guided attention¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RAIM definition\n",
    "# model definition -- use full attention when there is no guidance \n",
    "class RNNNetv1(nn.Module):\n",
    "    def __init__(self, batch_size, hidden_size):\n",
    "        super(RNNNetv1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.rnn = nn.LSTM(500, 200, 2, dropout=0.5)\n",
    "        self.attn = nn.Linear(10, 10)\n",
    "        self.attn1 = nn.Linear(60,10)\n",
    "\n",
    "        self.dense_h = nn.Linear(200,1)\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "\n",
    "        self.hidden2label = nn.Linear(200, 2)\n",
    "        self.hidden = self.init_hidden()\n",
    "        self.grucell = nn.GRUCell(500, 200)\n",
    "        \n",
    "        self.mlp_for_x      = nn.Linear(500,1, bias=False)\n",
    "        self.mlp_for_hidden = nn.Linear(200,12,bias=True)\n",
    "        \n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(self.batch_size, self.hidden_size))\n",
    "\n",
    "\n",
    "    def forward(self, x, guidance):        \n",
    "        for i in range(12):            \n",
    "            tt = x[:,0:i+1,:].reshape(self.batch_size, (i+1)* x[:,0:i+1,:].shape[2])\n",
    "            if i<11:\n",
    "                padding = torch.zeros(self.batch_size, 6000-tt.shape[1])\n",
    "                self.temp1 = torch.cat((tt, padding),1)\n",
    "            else:\n",
    "                self.temp1 = tt\n",
    "           \n",
    "            self.input_padded = self.temp1.reshape(10,12,500)\n",
    "            \n",
    "            #### multuply with guidance #######\n",
    "            temp_guidance = torch.zeros(10,12,1)\n",
    "            \n",
    "            temp_guidance[:,0:i+1,:] = guidance[:,0:i+1,:]\n",
    "          \n",
    "            if i>0:\n",
    "               \n",
    "                zero_idx = np.where(torch.sum(guidance[:,:i,0], dim=1)==0)\n",
    "                if len(zero_idx[0])>0:\n",
    "\n",
    "                    temp_guidance[zero_idx[0],:i,0] = 1\n",
    "\n",
    "            temp_guidance[:,i,:] = 1\n",
    "\n",
    "            self.guided_input = torch.mul(self.input_padded, temp_guidance)\n",
    "            \n",
    "            ######### MLP ###########\n",
    "            self.t1 = self.mlp_for_x(self.guided_input) + self.mlp_for_hidden(self.hidden).reshape(10,12,1)\n",
    "            \n",
    "            ######### softmax-> multiply->  context vector ###########\n",
    "            self.t1_softmax = self.softmax(self.t1)\n",
    "            final_output = torch.mul(self.input_padded, self.t1_softmax)\n",
    "\n",
    "            context_vec = torch.sum(final_output,dim=1)            \n",
    "            \n",
    "            self.hx = self.grucell(context_vec, self.hidden)\n",
    "            self.hidden = self.hx\n",
    "            \n",
    "        y  = self.hidden2label(self.hidden)\n",
    "        return self.hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input shape:', torch.Size([10, 12, 500]))\n",
      "torch.Size([10, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_tr = np.load('X_input_RAIM.npy')\n",
    "y_target = np.load('Y_target.npy')\n",
    "y_tr = np.load('Y_guidance.npy')\n",
    "\n",
    "trainset_v1 = TensorDataset(torch.from_numpy(x_tr.astype('float32')), torch.from_numpy(y_tr.astype('float32')),torch.from_numpy(y_guidance.astype('float32')))\n",
    "trainloader_v1 = torch.utils.data.DataLoader(trainset_v1, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader_v1)\n",
    "X_samples = dataiter.next()\n",
    "\n",
    "trainset_v1 = TensorDataset(torch.from_numpy(x_tr.astype('float32')), torch.from_numpy(y_tr.astype('float32')),torch.from_numpy(y_guidance.astype('float32')))\n",
    "trainloader_v1 = torch.utils.data.DataLoader(trainset_v1, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader_v1)\n",
    "\n",
    "print('input shape:', X_samples[0].shape)\n",
    "\n",
    "model = RNNNetv1(hidden_size = 200, batch_size = 10)\n",
    "output = model(X_samples[0], X_samples[2])\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train RAIM with medication-guided attention¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('input shape:', torch.Size([10, 12, 500]))\n",
      "torch.Size([10, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_tr = np.load('X_input_RAIM.npy')\n",
    "y_target = np.load('Y_target.npy')\n",
    "y_tr = np.load('Y_guidance_med.npy')\n",
    "\n",
    "trainset_v1 = TensorDataset(torch.from_numpy(x_tr.astype('float32')), torch.from_numpy(y_tr.astype('float32')),torch.from_numpy(y_target.astype('float32')))\n",
    "trainloader_v1 = torch.utils.data.DataLoader(trainset_v1, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader_v1)\n",
    "X_samples = dataiter.next()\n",
    "\n",
    "print('input shape:', X_samples[0].shape)\n",
    "\n",
    "model = RNNNetv1(hidden_size = 200, batch_size = 10)\n",
    "output = model(X_samples[0], X_samples[2])\n",
    "print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Train RAIM with both guidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 200])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siddharthbiswal/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:60: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_tr = np.load('X_input_RAIM.npy')\n",
    "y_target = np.load('Y_target.npy')\n",
    "y_tr = np.load('Y_guidance_combined.npy')\n",
    "\n",
    "trainset_v1 = TensorDataset(torch.from_numpy(x_tr.astype('float32')), torch.from_numpy(y_tr.astype('float32')),torch.from_numpy(y_target.astype('float32')))\n",
    "trainloader_v1 = torch.utils.data.DataLoader(trainset_v1, batch_size=32, shuffle=True, num_workers=2)\n",
    "\n",
    "dataiter = iter(trainloader_v1)\n",
    "X_samples = dataiter.next()\n",
    "\n",
    "\n",
    "model = RNNNetv1(hidden_size = 200, batch_size = 10)\n",
    "output = model(X_samples[0], X_samples[2])\n",
    "print(output.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
